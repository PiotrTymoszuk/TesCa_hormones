@article{He2016,
abstract = {At the late 1940s, 17$\beta$-HSD1 was discovered as the first member of the 17$\beta$-HSD family with its gene cloned. The three-dimensional structure of human 17$\beta$-HSD1 is the first example of any human steroid converting enzyme. The human enzyme's structure and biological function have thus been studied extensively in the last two decades. In humans, the enzyme is expressed in placenta, ovary, endometrium and breast. The high activity of estrogen activation provides the basis of 17$\beta$-HSD1's implication in estrogen-dependent diseases, such as breast cancer, endometriosis and non-small cell lung carcinomas. Its dual function in estrogen activation and androgen inactivation has been revealed in molecular and breast cancer cell levels, significantly stimulating the proliferation of such cells. The enzyme's overexpression in breast cancer was demonstrated by clinical samples. Inhibition of human 17$\beta$-HSD1 led to xenograft tumor shrinkage. Unfortunately, through decades of studies, there is still no drug using the enzyme's inhibitors available. This is due to the difficulty to get rid of the estrogenic activity of its inhibitors, which are mostly estrogen analogues. New non-steroid inhibitors for the enzyme provide new hope for non-estrogenic inhibitors of the enzyme.},
author = {He, Wanhong and Gauri, Misra and Li, Tang and Wang, Ruixuan and Lin, Sheng Xiang},
doi = {10.1016/J.GENE.2016.04.031},
issn = {18790038},
journal = {Gene},
keywords = {17$\beta$-hydroxysteroid dehydrogenase (17$\beta$-HSD),Breast cancer,Dual sex-hormone modulation,Estrogen dependent disease,High activity in estrogen synthesis,Narrow binding tunnel},
month = {aug},
number = {1},
pages = {54},
pmid = {27102893},
publisher = {NIH Public Access},
title = {{Current knowledge of the multifunctional 17$\beta$-hydroxysteroid dehydrogenase type 1 (HSD17B1)}},
url = {/pmc/articles/PMC6649686/ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6649686/},
volume = {588},
year = {2016}
}
@article{Hakkarainen2018,
abstract = {The pituitary gonadotrophins and testosterone are the main hormonal regulators of spermatogenesis, but estradiol is also known to play a role in the process. The hormonal responses in the testis are partially mediated by somatic Sertoli cells that provide nutritional and physical support for differentiating male germ cells. Hydroxysteroid (17b) dehydrogenase 1 (HSD17B1) is a steroidogenic enzyme that especially catalyzes the conversion of low potent 17keto-steroids to highly potent 17$\beta$-hydroxysteroids. In this study,we showthat Hsd17b1 is highly expressedinSertoli cells of fetal and newborn mice, and HSD17B1 knockout males present with disrupted spermatogenesis with major defects, particularly in the head shape of elongating spermatids. The cell-cell junctions between Sertoli cells and germ cells were disrupted in the HSD17B1 knockout mice. This resulted in complications in the orientation of elongating spermatids in the seminiferous epithelium, reduced sperm production, and morphologically abnormal spermatozoa. We also showed that the Sertoli cell-expressed HSD17B1 participates in testicular steroid synthesis, evidenced by a compensatory up-regulation ofHSD17B3 inLeydig cells.These results revealed a novel role forHSD17B1inthe control of spermatogenesis and male fertility, and that Sertoli cells significantly contribute to steroid synthesis in the testis.},
author = {Hakkarainen, Janne and Zhang, Fu Ping and Jokela, Heli and Mayerhofer, Artur and Behr, R{\"{u}}diger and Cisneros-Montalvo, Sheyla and Nurmio, Mirja and Toppari, Jorma and Ohlsson, Claes and Kotaja, Noora and Sipil{\"{a}}, Petra and Poutanen, Matti},
doi = {10.1096/FJ.201700921R},
issn = {1530-6860},
journal = {FASEB journal : official publication of the Federation of American Societies for Experimental Biology},
keywords = {17-Hydroxysteroid Dehydrogenases / biosynthesis*,17-Hydroxysteroid Dehydrogenases / genetics,Animals,Enzymologic / physiology*,Fertility / physiology*,Fu-Ping Zhang,Gene Expression Regulation,Janne Hakkarainen,Knockout,MEDLINE,Male,Matti Poutanen,Mice,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,PubMed Abstract,Research Support,Seminiferous Epithelium / cytology,Seminiferous Epithelium / enzymology,Sertoli Cells / cytology,Sertoli Cells / enzymology*,Spermatids / cytology,Spermatids / enzymology,Spermatogenesis / physiology*,Steroids / biosynthesis*,doi:10.1096/fj.201700921R,pmid:29401623},
month = {jun},
number = {6},
pages = {3229--3241},
pmid = {29401623},
publisher = {FASEB J},
title = {{Hydroxysteroid (17$\beta$) dehydrogenase 1 expressed by Sertoli cells contributes to steroid synthesis and is required for male fertility}},
url = {https://pubmed.ncbi.nlm.nih.gov/29401623/},
volume = {32},
year = {2018}
}
@article{Hilborn2017,
abstract = {Sex steroid hormones such as estrogens and androgens are involved in the development and differentiation of the breast tissue. The activity and concentration of sex steroids is determined by the availability from the circulation, and on local conversion. This conversion is primarily mediated by aromatase, steroid sulfatase, and 17$\beta$-hydroxysteroid dehydrogenases. In postmenopausal women, this is the primary source of estrogens in the breast. Up to 70-80% of all breast cancers express the estrogen receptor-a, responsible for promoting the growth of the tissue. Further, 60-80% express the androgen receptor, which has been shown to have tissue protective effects in estrogen receptor positive breast cancer, and a more ambiguous response in estrogen receptor negative breast cancers. In this review, we summarize the function and clinical relevance in cancer for 17$\beta$-hydroxysteroid dehydrogenases 1, which facilitates the reduction of estrone to estradiol, dehydroepiandrosterone to androstendiol and dihydrotestosterone to 3a- and 3$\beta$-diol as well as 17$\beta$-hydroxysteroid dehydrogenases 2 which mediates the oxidation of estradiol to estrone, testosterone to androstenedione and androstendiol to dehydroepiandrosterone. The expression of 17$\beta$-hydroxysteroid dehydrogenases 1 and 2 alone and in combination has been shown to predict patient outcome, and inhibition of 17$\beta$-hydroxysteroid dehydrogenases 1 has been proposed to be a prime candidate for inhibition in patients who develop aromatase inhibitor resistance or in combination with aromatase inhibitors as a first line treatment. Here we review the status of inhibitors against 17$\beta$-hydroxysteroid dehydrogenases 1. In addition, we review the involvement of 17$\beta$-hydroxysteroid dehydrogenases 4, 5, 7, and 14 in breast cancer.},
author = {Hilborn, Erik and St{\aa}l, Olle and Jansson, Agneta},
doi = {10.18632/ONCOTARGET.15547},
issn = {19492553},
journal = {Oncotarget},
keywords = {Androgens,Breast cancer,Estrogens,HSD17B1,HSD17B2},
month = {may},
number = {18},
pages = {30552},
pmid = {28430630},
publisher = {Impact Journals, LLC},
title = {{Estrogen and androgen-converting enzymes 17$\beta$-hydroxysteroid dehydrogenase and their involvement in cancer: with a special focus on 17$\beta$-hydroxysteroid dehydrogenase type 1, 2, and breast cancer}},
url = {/pmc/articles/PMC5444764/ /pmc/articles/PMC5444764/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5444764/},
volume = {8},
year = {2017}
}
@misc{Meyer2022,
abstract = {Provides an extensible framework for the efficient calculation of auto- and cross-proximities, along with implementations of the most popular ones.},
author = {Meyer, David and Buchta, Christian},
title = {{proxy: Distance and Similarity Measures}},
url = {https://cran.r-project.org/web/packages/proxy/index.html},
year = {2022}
}
@article{VandenEynde1995,
abstract = {Human melanoma MZ2-MEL expresses several distinct antigens that are recognized by autologous cytolytic T lymphocytes (CTL). Some of these antigens are encoded by genes MAGE-1, MAGE-3, and BAGE, which are expressed in a large fraction of tumors of various histological types but are silent in normal adult tissues with the exception of testis. We report here the identification of the gene coding for MZ2-F, another antigen recognized by autologous CTL on MZ2-MEL cells. This gene, which was named GAGE-l, is not related to any presently known gene. It belongs to a family of genes that are expressed in a variety of tumors but not in normal tissues, except for the testis. Antigenic peptide YILPRPRRY, which is encoded by GAGE-l, is recognized by anti-MZ2-F CTL on class I molecule HLA-Cw6. The two genes of the GAGE family that code for this peptide, namely GAGE-1 and GAGE-2, are expressed in a significant proportion of melanomas (24%), sarcomas (25%), non-small cell lung cancers (19%), head and neck tumors (19%), and bladder tumors (12%). About 50% of melanoma patients carry on their tumor at least one of the presently defined antigens encoded by the MAGE, BAGE, and GAGE genes. {\textcopyright} 1995, Rockefeller University Press., All rights reserved.},
author = {{Van den Eynde}, Beno{\^{i}}t and Peeters, Olivier and {De Backer}, Olivier and Gaugler, B{\'{e}}atrice and Luca, Sophie and Boon, Thierry},
doi = {10.1084/JEM.182.3.689},
issn = {0022-1007},
journal = {The Journal of experimental medicine},
keywords = {Amino Acid Sequence,Animals,Antigens,B Van den Eynde,Base Sequence,Cell Line,Chlorocebus aethiops,Comparative Study,Complementary / genetics,Cultured,Cytotoxic / immunology*,DNA,Epitopes / chemistry,Epitopes / immunology,Fetus / metabolism,Gene Expression Regulation,HLA-C Antigens / immunology,HeLa Cells,Humans,MEDLINE,Melanoma / genetics,Melanoma / immunology*,Melanoma-Specific Antigens,Messenger / biosynthesis,Molecular Sequence Data,Multigene Family*,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neoplasm / biosynthesis,Neoplasm / genetics,Neoplasm / genetics*,Neoplasm / immunology,Neoplasm Proteins*,Neoplasms / immunology,Neoplastic,Non-U.S. Gov't,O Peeters,Organ Specificity,PMC2192160,Peptide Fragments / chemistry,Peptide Fragments / immunology,PubMed Abstract,RNA,Research Support,Sequence Alignment,Sequence Homology,T Boon,T-Lymphocytes,Transfection,Transformed,Tumor Cells,doi:10.1084/jem.182.3.689,pmid:7544395},
month = {sep},
number = {3},
pages = {689--698},
pmid = {7544395},
publisher = {J Exp Med},
title = {{A new family of genes coding for an antigen recognized by autologous cytolytic T lymphocytes on a human melanoma}},
url = {https://pubmed.ncbi.nlm.nih.gov/7544395/},
volume = {182},
year = {1995}
}
@article{Nin2023,
abstract = {Tumour-specific antigens have been an area of interest in cancer therapy since their discovery in the middle of the 20th century. In the era of immune-based cancer therapeutics, redirecting our immune cells to target these tumour-specific antigens has become even more relevant. Cancer-testis antigens (CTAs) are a class of antigens with an expression specific to the testis and cancer cells. CTAs have also been demonstrated to be expressed in a wide variety of cancers. Due to their frequency and specificity of expression in a multitude of cancers, CTAs have been particularly attractive as cancer-specific therapeutic targets. There is now a rapid expansion of CTAs being identified and many studies have been conducted to correlate CTA expression with cancer and therapy-resistant phenotypes. Furthermore, there is an increasing number of clinical trials involving using some of these CTAs as molecular targets in pharmacological and immune-targeted therapeutics for various cancers. This review will summarise the current knowledge of the biology of known CTAs in tumorigenesis and the regulation of CTA genes. CTAs as molecular targets and the therapeutic implications of these CTA-targeted anticancer strategies will also be discussed.},
author = {Nin, Dawn Sijin and Deng, Lih Wen},
doi = {10.3390/CELLS12060926},
issn = {2073-4409},
journal = {Cells 2023, Vol. 12, Page 926},
keywords = {CT antigens,cancer,testis antigens},
month = {mar},
number = {6},
pages = {926},
pmid = {36980267},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Biology of Cancer-Testis Antigens and Their Therapeutic Implications in Cancer}},
url = {https://www.mdpi.com/2073-4409/12/6/926/htm https://www.mdpi.com/2073-4409/12/6/926},
volume = {12},
year = {2023}
}
@article{Liu2018,
abstract = {For a decade, The Cancer Genome Atlas (TCGA) program collected clinicopathologic annotation data along with multi-platform molecular profiles of more than 11,000 human tumors across 33 different cancer types. TCGA clinical data contain key features representing the democratized nature of the data collection process. To ensure proper use of this large clinical dataset associated with genomic features, we developed a standardized dataset named the TCGA Pan-Cancer Clinical Data Resource (TCGA-CDR), which includes four major clinical outcome endpoints. In addition to detailing major challenges and statistical limitations encountered during the effort of integrating the acquired clinical data, we present a summary that includes endpoint usage recommendations for each cancer type. These TCGA-CDR findings appear to be consistent with cancer genomics studies independent of the TCGA effort and provide opportunities for investigating cancer biology using clinical correlates at an unprecedented scale. Analysis of clinicopathologic annotations for over 11,000 cancer patients in the TCGA program leads to the generation of TCGA Clinical Data Resource, which provides recommendations of clinical outcome endpoint usage for 33 cancer types.},
author = {Liu, Jianfang and Lichtenberg, Tara and Hoadley, Katherine A. and Poisson, Laila M. and Lazar, Alexander J. and Cherniack, Andrew D. and Kovatich, Albert J. and Benz, Christopher C. and Levine, Douglas A. and Lee, Adrian V. and Omberg, Larsson and Wolf, Denise M. and Shriver, Craig D. and Thorsson, Vesteinn and Caesar-Johnson, Samantha J. and Demchok, John A. and Felau, Ina and Kasapi, Melpomeni and Ferguson, Martin L. and Hutter, Carolyn M. and Sofia, Heidi J. and Tarnuzzer, Roy and Wang, Zhining and Yang, Liming and Zenklusen, Jean C. and Zhang, Jiashan (Julia) and Chudamani, Sudha and Liu, Jia and Lolla, Laxmi and Naresh, Rashi and Pihl, Todd and Sun, Qiang and Wan, Yunhu and Wu, Ye and Cho, Juok and DeFreitas, Timothy and Frazer, Scott and Gehlenborg, Nils and Getz, Gad and Heiman, David I. and Kim, Jaegil and Lawrence, Michael S. and Lin, Pei and Meier, Sam and Noble, Michael S. and Saksena, Gordon and Voet, Doug and Zhang, Hailei and Bernard, Brady and Chambwe, Nyasha and Dhankani, Varsha and Knijnenburg, Theo and Kramer, Roger and Leinonen, Kalle and Liu, Yuexin and Miller, Michael and Reynolds, Sheila and Shmulevich, Ilya and Thorsson, Vesteinn and Zhang, Wei and Akbani, Rehan and Broom, Bradley M. and Hegde, Apurva M. and Ju, Zhenlin and Kanchi, Rupa S. and Korkut, Anil and Li, Jun and Liang, Han and Ling, Shiyun and Liu, Wenbin and Lu, Yiling and Mills, Gordon B. and Ng, Kwok Shing and Rao, Arvind and Ryan, Michael and Wang, Jing and Weinstein, John N. and Zhang, Jiexin and Abeshouse, Adam and Armenia, Joshua and Chakravarty, Debyani and Chatila, Walid K. and de Bruijn, Ino and Gao, Jianjiong and Gross, Benjamin E. and Heins, Zachary J. and Kundra, Ritika and La, Konnor and Ladanyi, Marc and Luna, Augustin and Nissan, Moriah G. and Ochoa, Angelica and Phillips, Sarah M. and Reznik, Ed and Sanchez-Vega, Francisco and Sander, Chris and Schultz, Nikolaus and Sheridan, Robert and Sumer, S. Onur and Sun, Yichao and Taylor, Barry S. and Wang, Jioajiao and Zhang, Hongxin and Anur, Pavana and Peto, Myron and Spellman, Paul and Benz, Christopher and Stuart, Joshua M. and Wong, Christopher K. and Yau, Christina and Hayes, D. Neil and Parker, Joel S. and Wilkerson, Matthew D. and Ally, Adrian and Balasundaram, Miruna and Bowlby, Reanne and Brooks, Denise and Carlsen, Rebecca and Chuah, Eric and Dhalla, Noreen and Holt, Robert and Jones, Steven J.M. and Kasaian, Katayoon and Lee, Darlene and Ma, Yussanne and Marra, Marco A. and Mayo, Michael and Moore, Richard A. and Mungall, Andrew J. and Mungall, Karen and Robertson, A. Gordon and Sadeghi, Sara and Schein, Jacqueline E. and Sipahimalani, Payal and Tam, Angela and Thiessen, Nina and Tse, Kane and Wong, Tina and Berger, Ashton C. and Beroukhim, Rameen and Cherniack, Andrew D. and Cibulskis, Carrie and Gabriel, Stacey B. and Gao, Galen F. and Ha, Gavin and Meyerson, Matthew and Schumacher, Steven E. and Shih, Juliann and Kucherlapati, Melanie H. and Kucherlapati, Raju S. and Baylin, Stephen and Cope, Leslie and Danilova, Ludmila and Bootwalla, Moiz S. and Lai, Phillip H. and Maglinte, Dennis T. and {Van Den Berg}, David J. and Weisenberger, Daniel J. and Auman, J. Todd and Balu, Saianand and Bodenheimer, Tom and Fan, Cheng and Hoadley, Katherine A. and Hoyle, Alan P. and Jefferys, Stuart R. and Jones, Corbin D. and Meng, Shaowu and Mieczkowski, Piotr A. and Mose, Lisle E. and Perou, Amy H. and Perou, Charles M. and Roach, Jeffrey and Shi, Yan and Simons, Janae V. and Skelly, Tara and Soloway, Matthew G. and Tan, Donghui and Veluvolu, Umadevi and Fan, Huihui and Hinoue, Toshinori and Laird, Peter W. and Shen, Hui and Zhou, Wanding and Bellair, Michelle and Chang, Kyle and Covington, Kyle and Creighton, Chad J. and Dinh, Huyen and Doddapaneni, Harsha Vardhan and Donehower, Lawrence A. and Drummond, Jennifer and Gibbs, Richard A. and Glenn, Robert and Hale, Walker and Han, Yi and Hu, Jianhong and Korchina, Viktoriya and Lee, Sandra and Lewis, Lora and Li, Wei and Liu, Xiuping and Morgan, Margaret and Morton, Donna and Muzny, Donna and Santibanez, Jireh and Sheth, Margi and Shinbro, Eve and Wang, Linghua and Wang, Min and Wheeler, David A. and Xi, Liu and Zhao, Fengmei and Hess, Julian and Appelbaum, Elizabeth L. and Bailey, Matthew and Cordes, Matthew G. and Ding, Li and Fronick, Catrina C. and Fulton, Lucinda A. and Fulton, Robert S. and Kandoth, Cyriac and Mardis, Elaine R. and McLellan, Michael D. and Miller, Christopher A. and Schmidt, Heather K. and Wilson, Richard K. and Crain, Daniel and Curley, Erin and Gardner, Johanna and Lau, Kevin and Mallery, David and Morris, Scott and Paulauskis, Joseph and Penny, Robert and Shelton, Candace and Shelton, Troy and Sherman, Mark and Thompson, Eric and Yena, Peggy and Bowen, Jay and Gastier-Foster, Julie M. and Gerken, Mark and Leraas, Kristen M. and Lichtenberg, Tara M. and Ramirez, Nilsa C. and Wise, Lisa and Zmuda, Erik and Corcoran, Niall and Costello, Tony and Hovens, Christopher and Carvalho, Andre L. and de Carvalho, Ana C. and Fregnani, Jos{\'{e}} H. and Longatto-Filho, Adhemar and Reis, Rui M. and Scapulatempo-Neto, Cristovam and Silveira, Henrique C.S. and Vidal, Daniel O. and Burnette, Andrew and Eschbacher, Jennifer and Hermes, Beth and Noss, Ardene and Singh, Rosy and Anderson, Matthew L. and Castro, Patricia D. and Ittmann, Michael and Huntsman, David and Kohl, Bernard and Le, Xuan and Thorp, Richard and Andry, Chris and Duffy, Elizabeth R. and Lyadov, Vladimir and Paklina, Oxana and Setdikova, Galiya and Shabunin, Alexey and Tavobilov, Mikhail and McPherson, Christopher and Warnick, Ronald and Berkowitz, Ross and Cramer, Daniel and Feltmate, Colleen and Horowitz, Neil and Kibel, Adam and Muto, Michael and Raut, Chandrajit P. and Malykh, Andrei and Barnholtz-Sloan, Jill S. and Barrett, Wendi and Devine, Karen and Fulop, Jordonna and Ostrom, Quinn T. and Shimmel, Kristen and Wolinsky, Yingli and Sloan, Andrew E. and {De Rose}, Agostino and Giuliante, Felice and Goodman, Marc and Karlan, Beth Y. and Hagedorn, Curt H. and Eckman, John and Harr, Jodi and Myers, Jerome and Tucker, Kelinda and Zach, Leigh Anne and Deyarmin, Brenda and Hu, Hai and Kvecher, Leonid and Larson, Caroline and Mural, Richard J. and Somiari, Stella and Vicha, Ales and Zelinka, Tomas and Bennett, Joseph and Iacocca, Mary and Rabeno, Brenda and Swanson, Patricia and Latour, Mathieu and Lacombe, Louis and T{\^{e}}tu, Bernard and Bergeron, Alain and McGraw, Mary and Staugaitis, Susan M. and Chabot, John and Hibshoosh, Hanina and Sepulveda, Antonia and Su, Tao and Wang, Timothy and Potapova, Olga and Voronina, Olga and Desjardins, Laurence and Mariani, Odette and Roman-Roman, Sergio and Sastre, Xavier and Stern, Marc Henri and Cheng, Feixiong and Signoretti, Sabina and Berchuck, Andrew and Bigner, Darell and Lipp, Eric and Marks, Jeffrey and McCall, Shannon and McLendon, Roger and Secord, Angeles and Sharp, Alexis and Behera, Madhusmita and Brat, Daniel J. and Chen, Amy and Delman, Keith and Force, Seth and Khuri, Fadlo and Magliocca, Kelly and Maithel, Shishir and Olson, Jeffrey J. and Owonikoko, Taofeek and Pickens, Alan and Ramalingam, Suresh and Shin, Dong M. and Sica, Gabriel and {Van Meir}, Erwin G. and Zhang, Hongzheng and Eijckenboom, Wil and Gillis, Ad and Korpershoek, Esther and Looijenga, Leendert and Oosterhuis, Wolter and Stoop, Hans and van Kessel, Kim E. and Zwarthoff, Ellen C. and Calatozzolo, Chiara and Cuppini, Lucia and Cuzzubbo, Stefania and DiMeco, Francesco and Finocchiaro, Gaetano and Mattei, Luca and Perin, Alessandro and Pollo, Bianca and Chen, Chu and Houck, John and Lohavanichbutr, Pawadee and Hartmann, Arndt and Stoehr, Christine and Stoehr, Robert and Taubert, Helge and Wach, Sven and Wullich, Bernd and Kycler, Witold and Murawa, Dawid and Wiznerowicz, Maciej and Chung, Ki and Edenfield, W. Jeffrey and Martin, Julie and Baudin, Eric and Bubley, Glenn and Bueno, Raphael and {De Rienzo}, Assunta and Richards, William G. and Kalkanis, Steven and Mikkelsen, Tom and Noushmehr, Houtan and Scarpace, Lisa and Girard, Nicolas and Aymerich, Marta and Campo, Elias and Gin{\'{e}}, Eva and Guillermo, Armando L{\'{o}}pez and {Van Bang}, Nguyen and Hanh, Phan Thi and Phu, Bui Duc and Tang, Yufang and Colman, Howard and Evason, Kimberley and Dottino, Peter R. and Martignetti, John A. and Gabra, Hani and Juhl, Hartmut and Akeredolu, Teniola and Stepa, Serghei and Hoon, Dave and Ahn, Keunsoo and Kang, Koo Jeong and Beuschlein, Felix and Breggia, Anne and Birrer, Michael and Bell, Debra and Borad, Mitesh and Bryce, Alan H. and Castle, Erik and Chandan, Vishal and Cheville, John and Copland, John A. and Farnell, Michael and Flotte, Thomas and Giama, Nasra and Ho, Thai and Kendrick, Michael and Kocher, Jean Pierre and Kopp, Karla and Moser, Catherine and Nagorney, David and O'Brien, Daniel and O'Neill, Brian Patrick and Patel, Tushar and Petersen, Gloria and Que, Florencia and Rivera, Michael and Roberts, Lewis and Smallridge, Robert and Smyrk, Thomas and Stanton, Melissa and Thompson, R. Houston and Torbenson, Michael and Yang, Ju Dong and Zhang, Lizhi and Brimo, Fadi and Ajani, Jaffer A. and {Angulo Gonzalez}, Ana Maria and Behrens, Carmen and Bondaruk, Jolanta and Broaddus, Russell and Czerniak, Bogdan and Esmaeli, Bita and Fujimoto, Junya and Gershenwald, Jeffrey and Guo, Charles and Logothetis, Christopher and Meric-Bernstam, Funda and Moran, Cesar and Ramondetta, Lois and Rice, David and Sood, Anil and Tamboli, Pheroze and Thompson, Timothy and Troncoso, Patricia and Tsao, Anne and Wistuba, Ignacio and Carter, Candace and Haydu, Lauren and Hersey, Peter and Jakrot, Valerie and Kakavand, Hojabr and Kefford, Richard and Lee, Kenneth and Long, Georgina and Mann, Graham and Quinn, Michael and Saw, Robyn and Scolyer, Richard and Shannon, Kerwin and Spillane, Andrew and Stretch, Jonathan and Synott, Maria and Thompson, John and Wilmott, James and Al-Ahmadie, Hikmat and Chan, Timothy A. and Ghossein, Ronald and Gopalan, Anuradha and Levine, Douglas A. and Reuter, Victor and Singer, Samuel and Singh, Bhuvanesh and Tien, Nguyen Viet and Broudy, Thomas and Mirsaidi, Cyrus and Nair, Praveen and Drwiega, Paul and Miller, Judy and Smith, Jennifer and Zaren, Howard and Park, Joong Won and Hung, Nguyen Phi and Kebebew, Electron and Linehan, W. Marston and Metwalli, Adam R. and Pacak, Karel and Pinto, Peter A. and Schiffman, Mark and Schmidt, Laura S. and Vocke, Cathy D. and Wentzensen, Nicolas and Worrell, Robert and Yang, Hannah and Moncrieff, Marc and Goparaju, Chandra and Melamed, Jonathan and Pass, Harvey and Botnariuc, Natalia and Caraman, Irina and Cernat, Mircea and Chemencedji, Inga and Clipca, Adrian and Doruc, Serghei and Gorincioi, Ghenadie and Mura, Sergiu and Pirtac, Maria and Stancul, Irina and Tcaciuc, Diana and Albert, Monique and Alexopoulou, Iakovina and Arnaout, Angel and Bartlett, John and Engel, Jay and Gilbert, Sebastien and Parfitt, Jeremy and Sekhon, Harman and Thomas, George and Rassl, Doris M. and Rintoul, Robert C. and Bifulco, Carlo and Tamakawa, Raina and Urba, Walter and Hayward, Nicholas and Timmers, Henri and Antenucci, Anna and Facciolo, Francesco and Grazi, Gianluca and Marino, Mirella and Merola, Roberta and de Krijger, Ronald and Gimenez-Roqueplo, Anne Paule and Pich{\'{e}}, Alain and Chevalier, Simone and McKercher, Ginette and Birsoy, Kivanc and Barnett, Gene and Brewer, Cathy and Farver, Carol and Naska, Theresa and Pennell, Nathan A. and Raymond, Daniel and Schilero, Cathy and Smolenski, Kathy and Williams, Felicia and Morrison, Carl and Borgia, Jeffrey A. and Liptay, Michael J. and Pool, Mark and Seder, Christopher W. and Junker, Kerstin and Omberg, Larsson and Dinkin, Mikhail and Manikhas, George and Alvaro, Domenico and Bragazzi, Maria Consiglia and Cardinale, Vincenzo and Carpino, Guido and Gaudio, Eugenio and Chesla, David and Cottingham, Sandra and Dubina, Michael and Moiseenko, Fedor and Dhanasekaran, Renumathy and Becker, Karl Friedrich and Janssen, Klaus Peter and Slotta-Huspenina, Julia and Abdel-Rahman, Mohamed H. and Aziz, Dina and Bell, Sue and Cebulla, Colleen M. and Davis, Amy and Duell, Rebecca and Elder, J. Bradley and Hilty, Joe and Kumar, Bahavna and Lang, James and Lehman, Norman L. and Mandt, Randy and Nguyen, Phuong and Pilarski, Robert and Rai, Karan and Schoenfield, Lynn and Senecal, Kelly and Wakely, Paul and Hansen, Paul and Lechan, Ronald and Powers, James and Tischler, Arthur and Grizzle, William E. and Sexton, Katherine C. and Kastl, Alison and Henderson, Joel and Porten, Sima and Waldmann, Jens and Fassnacht, Martin and Asa, Sylvia L. and Schadendorf, Dirk and Couce, Marta and Graefen, Markus and Huland, Hartwig and Sauter, Guido and Schlomm, Thorsten and Simon, Ronald and Tennstedt, Pierre and Olabode, Oluwole and Nelson, Mark and Bathe, Oliver and Carroll, Peter R. and Chan, June M. and Disaia, Philip and Glenn, Pat and Kelley, Robin K. and Landen, Charles N. and Phillips, Joanna and Prados, Michael and Simko, Jeffry and Smith-McCune, Karen and VandenBerg, Scott and Roggin, Kevin and Fehrenbach, Ashley and Kendler, Ady and Sifri, Suzanne and Steele, Ruth and Jimeno, Antonio and Carey, Francis and Forgie, Ian and Mannelli, Massimo and Carney, Michael and Hernandez, Brenda and Campos, Benito and Herold-Mende, Christel and Jungk, Christin and Unterberg, Andreas and von Deimling, Andreas and Bossler, Aaron and Galbraith, Joseph and Jacobus, Laura and Knudson, Michael and Knutson, Tina and Ma, Deqin and Milhem, Mohammed and Sigmund, Rita and Godwin, Andrew K. and Madan, Rashna and Rosenthal, Howard G. and Adebamowo, Clement and Adebamowo, Sally N. and Boussioutas, Alex and Beer, David and Giordano, Thomas and Mes-Masson, Anne Marie and Saad, Fred and Bocklage, Therese and Landrum, Lisa and Mannel, Robert and Moore, Kathleen and Moxley, Katherine and Postier, Russel and Walker, Joan and Zuna, Rosemary and Feldman, Michael and Valdivieso, Federico and Dhir, Rajiv and Luketich, James and {Mora Pinero}, Edna M. and Quintero-Aguilo, Mario and Carlotti, Carlos Gilberto and {Dos Santos}, Jose Sebasti{\~{a}}o and Kemp, Rafael and Sankarankuty, Ajith and Tirapelli, Daniela and Catto, James and Agnew, Kathy and Swisher, Elizabeth and Creaney, Jenette and Robinson, Bruce and Shelley, Carl Simon and Godwin, Eryn M. and Kendall, Sara and Shipman, Cassaundra and Bradford, Carol and Carey, Thomas and Haddad, Andrea and Moyer, Jeffey and Peterson, Lisa and Prince, Mark and Rozek, Laura and Wolf, Gregory and Bowman, Rayleen and Fong, Kwun M. and Yang, Ian and Korst, Robert and Rathmell, W. Kimryn and Fantacone-Campbell, J. Leigh and Hooke, Jeffrey A. and Kovatich, Albert J. and Shriver, Craig D. and DiPersio, John and Drake, Bettina and Govindan, Ramaswamy and Heath, Sharon and Ley, Timothy and {Van Tine}, Brian and Westervelt, Peter and Rubin, Mark A. and Lee, Jung Il and Aredes, Nat{\'{a}}lia D. and Mariamidze, Armaz and Hu, Hai},
doi = {10.1016/J.CELL.2018.02.052},
issn = {1097-4172},
journal = {Cell},
keywords = {Databases,Extramural,Genetic,Genomics,Hai Hu,Humans,Jianfang Liu,Kaplan-Meier Estimate,MEDLINE,N.I.H.,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neoplasms / genetics,Neoplasms / mortality,Neoplasms / pathology*,Non-P.H.S.,PMC6066282,Proportional Hazards Models,PubMed Abstract,Research Support,Tara Lichtenberg,U.S. Gov't,doi:10.1016/j.cell.2018.02.052,pmid:29625055},
month = {apr},
number = {2},
pages = {400--416.e11},
pmid = {29625055},
publisher = {Cell},
title = {{An Integrated TCGA Pan-Cancer Clinical Data Resource to Drive High-Quality Survival Outcome Analytics}},
url = {https://pubmed.ncbi.nlm.nih.gov/29625055/},
volume = {173},
year = {2018}
}
@article{Fraley2011,
abstract = {Cluster analysis is the automated search for groups of related observations in a dataset. Most clustering done in practice is based largely on heuristic but intuitively reasonable procedures, and m...},
author = {Fraley, Chris and Raftery, Adrian E.},
doi = {10.1198/016214502760047131},
issn = {01621459},
journal = {https://doi.org/10.1198/016214502760047131},
keywords = {Bayes factor,Breast cancer diagnosis,Cluster analysis,EM algorithm,Gene expression microarray data,Markov chain Monte Carlo,Mixture model,Outliers,Spatial point process},
number = {458},
pages = {611--631},
publisher = {Taylor & Francis},
title = {{Model-Based Clustering, Discriminant Analysis, and Density Estimation}},
url = {https://www.tandfonline.com/doi/abs/10.1198/016214502760047131},
volume = {97},
year = {2011}
}
@misc{Fraley2022,
abstract = {Gaussian finite mixture models fitted via EM algorithm for model-based clustering, classification, and density estimation, including Bayesian regularization, dimension reduction for visualisation, and resampling-based inference.},
author = {Fraley, Chris and Raftery, Adrian E. and Scrucca, Luca},
month = {oct},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{mclust: Gaussian Mixture Modelling for Model-Based Clustering, Classification, and Density Estimation}},
url = {https://cran.r-project.org/package=mclust},
year = {2022}
}
@article{Ooms2023,
abstract = {Zero-dependency data frame to xlsx exporter based on 'libxlsxwriter'. Fast and no Java or Excel required.},
author = {Ooms, Jeroen and McNamara, John},
month = {jan},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{writexl: Export Data Frames to Excel 'xlsx' Format}},
url = {https://cran.r-project.org/package=writexl},
year = {2023}
}
@article{Grambsch1994,
abstract = {Nonproportional hazards can often be expressed by extending the Cox model to include time varying coefficients; e.g., for a single covariate, the hazard function for subject i is modelled as exp $\beta$(t)Zi(t). A common example is a treatment effect that decreases with time. We show that the function $\beta$(t) can be directly visualized by smoothing an appropriate residual plot. Also, many tests of proportional hazards, including those of Cox (1972), Gill & Schumacher (1987), Harrell (1986), Lin (1991), Moreau, O'Quigley & Mesbah (1985), Nagelkerke, Oosting & Hart (1984), O'Quigley & Pessione (1989), Schoenfeld (1980) and Wei (1984) are related to time-weighted score tests of the proportional hazards hypothesis, and can be visualized as a weighted least-squares line fitted to the residual plot.},
author = {Grambsch, Patricia M. and Therneau, Terry M.},
doi = {10.2307/2337123},
issn = {00063444},
journal = {Biometrika},
month = {aug},
number = {3},
pages = {515},
publisher = {JSTOR},
title = {{Proportional Hazards Tests and Diagnostics Based on Weighted Residuals}},
volume = {81},
year = {1994}
}
@article{Gerds2006,
abstract = {In survival analysis with censored data the mean squared error of prediction can be estimated by weighted averages of time-dependent residuals. Graf et al. (1999) suggested a robust weighting scheme based on the assumption that the censoring mechanism is independent of the covariates. We show consistency of the estimator. Furthermore, we show that a modified version of this estimator is consistent even when censoring and event times are only conditionally independent given the covariates. The modified estimators are derived on the basis of regression models for the censoring distribution. A simulation study and a real data example illustrate the results. {\textcopyright} 2006 WILEY-VCH Verlag GmbH & Co. KGaA.},
author = {Gerds, Thomas A. and Schumacher, Martin},
doi = {10.1002/BIMJ.200610301},
issn = {1521-4036},
journal = {Biometrical Journal},
keywords = {Brier Score,Censoring Bias,Inverse of Probability of Censoring Weighting,Model Validation,Survival Analysis},
month = {dec},
number = {6},
pages = {1029--1040},
pmid = {17240660},
publisher = {John Wiley & Sons, Ltd},
title = {{Consistent Estimation of the Expected Brier Score in General Survival Models with Right-Censored Event Times}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/bimj.200610301 https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.200610301 https://onlinelibrary.wiley.com/doi/10.1002/bimj.200610301},
volume = {48},
year = {2006}
}
@article{Csardi2006,
author = {Csardi, Gabor and Nepusz, Tamas},
journal = {InterJournal},
pages = {1695},
title = {{The igraph software package for complex network research}},
url = {https://igraph.org},
volume = {Complex Sy},
year = {2006}
}
@misc{Signorell2022,
abstract = {A collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author's intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The 'BigCamelCase' style was consequently applied to functions borrowed from contributed R packages as well.},
author = {Signorell, Andri},
month = {oct},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{DescTools: Tools for Descriptive Statistics}},
url = {https://cran.r-project.org/package=DescTools},
year = {2022}
}
@misc{Harrell2022,
abstract = {Contains many functions useful for data analysis, high-level graphics, utility operations, functions for computing sample size and power, simulation, importing and annotating datasets, imputing missing values, advanced table making, variable clustering, character string manipulation, conversion of R objects to LaTeX and html code, and recoding variables.},
author = {Harrell, Frank E. and Dupont, Charles},
month = {aug},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{Hmisc: Harrell Miscellaneous}},
url = {https://cran.r-project.org/package=Hmisc},
year = {2022}
}
@article{Sachs2017,
abstract = {Plots of the receiver operating characteristic (ROC) curve are ubiquitous in medical research. Designed to simultaneously display the operating characteristics at every possible value of a continuous diagnostic test, ROC curves are used in oncology to evaluate screening, diagnostic, prognostic and predictive biomarkers. I reviewed a sample of ROC curve plots from the major oncology journals in order to assess current trends in usage and design elements. My review suggests that ROC curve plots are often ineffective as statistical charts and that poor design obscures the relevant information the chart is intended to display. I describe my new R package that was created to address the shortcomings of existing tools. The package has functions to create informative ROC curve plots, with sensible defaults and a simple interface, for use in print or as an interactive web-based plot. A web application was developed to reach a broader audience of scientists who do not use R.},
author = {Sachs, Michael C.},
doi = {10.18637/jss.v079.c02},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sachs - 2017 - Plotroc A tool for plotting ROC curves.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Graphics,Interactive,Plots,ROC curves},
month = {aug},
number = {1},
pages = {1--19},
publisher = {American Statistical Association},
title = {{Plotroc: A tool for plotting ROC curves}},
url = {https://www.jstatsoft.org/index.php/jss/article/view/v079c02/v79c02.pdf https://www.jstatsoft.org/index.php/jss/article/view/v079c02},
volume = {79},
year = {2017}
}
@misc{Briatte2021,
abstract = {Geometries to plot network objects with 'ggplot2'.},
author = {Briatte, Fran{\c{c}}ois and Bojanowski, Michal and Canouil, Micka{\"{e}}l and Charlop-Powers, Zachary and Fisher, Jacob C. and Johnson, Kipp and Rinker, Tyler},
month = {jul},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{ggnetwork: Geometries to Plot Networks with 'ggplot2'}},
url = {https://cran.r-project.org/package=ggnetwork},
year = {2021}
}
@book{Wilke2019,
abstract = {First edition. Intro; Copyright; Table of Contents; Preface; Thoughts on Graphing Software and Figure-Preparation Pipelines; Conventions Used in This Book; Using Code Examples; O'Reilly Online Learning; How to Contact Us; Acknowledgments; Chapter 1. Introduction; Ugly, Bad, and Wrong Figures; Part I. From Data to Visualization; Chapter 2. Visualizing Data: Mapping Data onto Aesthetics; Aesthetics and Types of Data; Scales Map Data Values onto Aesthetics; Chapter 3. Coordinate Systems and Axes; Cartesian Coordinates; Nonlinear Axes; Coordinate Systems with Curved Axes; Chapter 4. Color Scales Color as a Tool to DistinguishColor to Represent Data Values; Color as a Tool to Highlight; Chapter 5. Directory of Visualizations; Amounts; Distributions; Proportions; x-y relationships; Geospatial Data; Uncertainty; Chapter 6. Visualizing Amounts; Bar Plots; Grouped and Stacked Bars; Dot Plots and Heatmaps; Chapter 7. Visualizing Distributions: Histograms and Density Plots; Visualizing a Single Distribution; Visualizing Multiple Distributions at the Same Time; Chapter 8. Visualizing Distributions: Empirical Cumulative Distribution Functions and Q-Q Plots Empirical Cumulative Distribution FunctionsHighly Skewed Distributions; Quantile-Quantile Plots; Chapter 9. Visualizing Many Distributions at Once; Visualizing Distributions Along the Vertical Axis; Visualizing Distributions Along the Horizontal Axis; Chapter 10. Visualizing Proportions; A Case for Pie Charts; A Case for Side-by-Side Bars; A Case for Stacked Bars and Stacked Densities; Visualizing Proportions Separately as Parts of the Total; Chapter 11. Visualizing Nested Proportions; Nested Proportions Gone Wrong; Mosaic Plots and Treemaps; Nested Pies; Parallel Sets Chapter 12. Visualizing Associations Among Two or More Quantitative VariablesScatterplots; Correlograms; Dimension Reduction; Paired Data; Chapter 13. Visualizing Time Series and Other Functions of an Independent Variable; Individual Time Series; Multiple Time Series and Dose-Response Curves; Time Series of Two or More Response Variables; Chapter 14. Visualizing Trends; Smoothing; Showing Trends with a Defined Functional Form; Detrending and Time-Series Decomposition; Chapter 15. Visualizing Geospatial Data; Projections; Layers; Choropleth Mapping; Cartograms Chapter 16. Visualizing UncertaintyFraming Probabilities as Frequencies; Visualizing the Uncertainty of Point Estimates; Visualizing the Uncertainty of Curve Fits; Hypothetical Outcome Plots; Part II. Principles of Figure Design; Chapter 17. The Principle of Proportional Ink; Visualizations Along Linear Axes; Visualizations Along Logarithmic Axes; Direct Area Visualizations; Chapter 18. Handling Overlapping Points; Partial Transparency and Jittering; 2D Histograms; Contour Lines; Chapter 19. Common Pitfalls of Color Use; Encoding Too Much or Irrelevant Information},
address = {Sebastopol},
author = {Wilke, Claus O},
booktitle = {O'Reilly Media},
edition = {1},
isbn = {1492031089},
pages = {389},
publisher = {O'Reilly Media},
title = {{Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures}},
year = {2019}
}
@article{Simon2011,
abstract = {We introduce a pathwise algorithm for the Cox proportional hazards model, regularized by convex combinations of l1 and l2 penalties (elastic net). Our algorithm fits via cyclical coordinate descent, and employs warm starts to find a solution along a regularization path. We demonstrate the efficacy of our algorithm on real and simulated data sets, and find considerable speedup between our algorithm and competing methods.},
author = {Simon, Noah and Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
doi = {10.18637/JSS.V039.I05},
issn = {1548-7660},
journal = {Journal of Statistical Software},
keywords = {Cox model,Elastic net,Lasso,Survival},
month = {mar},
number = {5},
pages = {1--13},
publisher = {American Statistical Association},
title = {{Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent}},
url = {https://www.jstatsoft.org/index.php/jss/article/view/v039i05},
volume = {39},
year = {2011}
}
@article{Zou2005,
abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p ≫ n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso. {\textcopyright} 2005 Royal Statistical Society.},
author = {Zou, Hui and Hastie, Trevor},
doi = {10.1111/j.1467-9868.2005.00503.x},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Grouping effect,LARS algorithm,Lasso,P ≫ n problem,Penalization,Variable selection},
month = {apr},
number = {2},
pages = {301--320},
title = {{Regularization and variable selection via the elastic net}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9868.2005.00503.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2005.00503.x https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2005.00503.x},
volume = {67},
year = {2005}
}
@article{Croux2007,
abstract = {The results of a standard principal component analysis (PCA) can be affected by the presence of outliers. Hence robust alternatives to PCA are needed. One of the most appealing robust methods for principal component analysis uses the Projection-Pursuit principle. Here, one projects the data on a lower-dimensional space such that a robust measure of variance of the projected data will be maximized. The Projection-Pursuit-based method for principal component analysis has recently been introduced in the field of chemometrics, where the number of variables is typically large. In this paper, it is shown that the currently available algorithm for robust Projection-Pursuit PCA performs poor in the presence of many variables. A new algorithm is proposed that is more suitable for the analysis of chemical data. Its performance is studied by means of simulation experiments and illustrated on some real data sets. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Croux, C. and Filzmoser, P. and Oliveira, M. R.},
doi = {10.1016/j.chemolab.2007.01.004},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Multivariate statistics,Numerical precision,Optimization,Outliers,Robustness,Scale estimators},
month = {jun},
number = {2},
pages = {218--225},
publisher = {Elsevier},
title = {{Algorithms for Projection-Pursuit robust principal component analysis}},
volume = {87},
year = {2007}
}
@article{Benjamin2019,
abstract = {Mutect2 is a somatic variant caller that uses local assembly and realignment to detect SNVs and indels. Assembly implies whole haplotypes and read pairs, rather than single bases, as the atomic units of biological variation and sequencing evidence, improving variant calling. Beyond local assembly and alignment, Mutect2 is based on several probabilistic models for genotyping and filtering that work well with and without a matched normal sample and for all sequencing depths.},
author = {Benjamin, David and Sato, Takuto and Cibulskis, Kristian and Getz, Gad and Stewart, Chip and Lichtenstein, Lee},
doi = {10.1101/861054},
journal = {bioRxiv},
keywords = {assembly,indel,mutect,somatic},
month = {dec},
pages = {861054},
publisher = {Cold Spring Harbor Laboratory},
title = {{Calling Somatic SNVs and Indels with Mutect2}},
url = {https://www.biorxiv.org/content/10.1101/861054v1 https://www.biorxiv.org/content/10.1101/861054v1.abstract},
year = {2019}
}
@article{Kassambara2016,
author = {Kassambara, Alboukadel and Kosinski, Marcin and Biecek, Przemyslaw},
title = {{survminer: Drawing Survival Curves using 'ggplot2'}},
url = {https://cran.r-project.org/package=survminer},
year = {2016}
}
@misc{Wilke2022,
abstract = {A 'ggplot2' extension that enables the rendering of complex formatted plot labels (titles, subtitles, facet labels, axis labels, etc.). Text boxes with automatic word wrap are also supported.},
author = {Wilke, Claus O and Wiernik, Brenton M},
month = {sep},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{ggtext: Improved Text Rendering Support for 'ggplot2'}},
url = {https://cran.r-project.org/package=ggtext},
year = {2022}
}
@article{Strobl2008,
abstract = {Background: Random forests are becoming increasingly popular in many scientific fields because they can cope with "small n large p" problems, complex interactions and even highly correlated predictor variables. Their variable importance measures have recently been suggested as screening tools for, e.g., gene expression studies. However, these variable importance measures show a bias towards correlated predictor variables. Results: We identify two mechanisms responsible for this finding: (i) A preference for the selection of correlated predictors in the tree building process and (ii) an additional advantage for correlated predictor variables induced by the unconditional permutation scheme that is employed in the computation of the variable importance measure. Based on these considerations we develop a new, conditional permutation scheme for the computation of the variable importance measure. Conclusion: The resulting conditional variable importance reflects the true impact of each predictor variable more reliably than the original marginal approach. {\textcopyright} 2008 Strobl et al; licensee BioMed Central Ltd.},
author = {Strobl, Carolin and Boulesteix, Anne Laure and Kneib, Thomas and Augustin, Thomas and Zeileis, Achim},
doi = {10.1186/1471-2105-9-307},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Strobl et al. - 2008 - Conditional variable importance for random forests.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Bioinformatics,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
month = {jul},
number = {1},
pages = {1--11},
pmid = {18620558},
publisher = {BioMed Central},
title = {{Conditional variable importance for random forests}},
url = {https://link.springer.com/articles/10.1186/1471-2105-9-307 https://link.springer.com/article/10.1186/1471-2105-9-307},
volume = {9},
year = {2008}
}
@article{Wickham2019,
abstract = {At a high level, the tidyverse is a language for solving data science challenges with R code. Its primary goal is to facilitate a conversation between a human and a computer about data. Less abstractly, the tidyverse is a collection of R packages that share a high-level design philosophy and low-level grammar and data structures, so that learning one package makes it easier to learn the next. The tidyverse encompasses the repeated tasks at the heart of every data science project: data import, tidying, manipulation, visualisation, and programming. We expect that almost every project will use multiple domain-specific packages outside of the tidyverse: our goal is to provide tooling for the most common challenges; not to solve every possible problem. Notably, the tidyverse doesn't include tools for statistical modelling or communication. These toolkits are critical for data science, but are so large that they merit separate treatment. The tidyverse package allows users to install all tidyverse packages with a single command. There are a number of projects that are similar in scope to the tidyverse. The closest is perhaps Bioconductor (Gentleman et al., 2004; Huber et al., 2015), which provides an ecosystem of packages that support the analysis of high-throughput genomic data.},
author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy and Fran{\c{c}}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas and Miller, Evan and Bache, Stephan and M{\"{u}}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
doi = {10.21105/joss.01686},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wickham et al. - 2019 - Welcome to the Tidyverse.pdf:pdf},
issn = {2475-9066},
journal = {Journal of Open Source Software},
month = {nov},
number = {43},
pages = {1686},
publisher = {The Open Journal},
title = {{Welcome to the Tidyverse}},
volume = {4},
year = {2019}
}
@article{Aran2017,
abstract = {Tissues are complex milieus consisting of numerous cell types. Several recent methods have attempted to enumerate cell subsets from transcriptomes. However, the available methods have used limited sources for training and give only a partial portrayal of the full cellular landscape. Here we present xCell, a novel gene signature-based method, and use it to infer 64 immune and stromal cell types. We harmonized 1822 pure human cell type transcriptomes from various sources and employed a curve fitting approach for linear comparison of cell types and introduced a novel spillover compensation technique for separating them. Using extensive in silico analyses and comparison to cytometry immunophenotyping, we show that xCell outperforms other methods. xCell is available at http://xCell.ucsf.edu/.},
author = {Aran, Dvir and Hu, Zicheng and Butte, Atul J.},
doi = {10.1186/s13059-017-1349-1},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aran, Hu, Butte - 2017 - xCell Digitally portraying the tissue cellular heterogeneity landscape.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Animal Genetics and Genomics,Bioinformatics,Evolutionary Biology,Human Genetics,Microbial Genetics and Genomics,Plant Genetics and Genomics},
month = {nov},
number = {1},
pages = {220},
pmid = {29141660},
publisher = {BioMed Central Ltd.},
title = {{xCell: Digitally portraying the tissue cellular heterogeneity landscape}},
url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1349-1},
volume = {18},
year = {2017}
}
@misc{Gohel2022,
abstract = {Create pretty tables for 'HTML', 'PDF', 'Microsoft Word' and 'Microsoft PowerPoint' documents from 'R Markdown'. Functions are provided to let users create tables, modify and format their content. It also extends package 'officer' that does not contain any feature for customized tabular reporting.},
author = {Gohel, David},
title = {{flextable: Functions for Tabular Reporting}},
url = {https://cran.r-project.org/web/packages/flextable/index.html},
year = {2022}
}
@book{Therneau2000,
address = {New York},
author = {Therneau, Terry M. and Grambsch, Patricia M.},
edition = {1},
isbn = {0-387-98784-3},
publisher = {Springer Verlag},
title = {{Modeling Survival Data: Extending the Cox Model}},
year = {2000}
}
@article{Tarca2009,
abstract = {Motivation: Gene expression class comparison studies may identify hundreds or thousands of genes as differentially expressed (DE) between sample groups. Gaining biological insight from the result of such experiments can be approached, for instance, by identifying the signaling pathways impacted by the observed changes. Most of the existing pathway analysis methods focus on either the number of DE genes observed in a given pathway (enrichment analysis methods), or on the correlation between the pathway genes and the class of the samples (functional class scoring methods). Both approaches treat the pathways as simple sets of genes, disregarding the complex gene interactions that these pathways are built to describe. Results: We describe a novel signaling pathway impact analysis (SPIA) that combines the evidence obtained from the classical enrichment analysis with a novel type of evidence, which measures the actual perturbation on a given pathway under a given condition. A bootstrap procedure is used to assess the significance of the observed total pathway perturbation. Using simulations we show that the evidence derived from perturbations is independent of the pathway enrichment evidence. This allows us to calculate a global pathway significance P-value, which combines the enrichment and perturbation P-values. We illustrate the capabilities of the novel method on four real datasets. The results obtained on these data show that SPIA has better specificity and more sensitivity than several widely used pathway analysis methods. {\textcopyright} The Author 2008. Published by Oxford University Press. All rights reserved.},
author = {Tarca, Adi Laurentiu and Draghici, Sorin and Khatri, Purvesh and Hassan, Sonia S. and Mittal, Pooja and Kim, Jung Sun and Kim, Chong Jai and Kusanovic, Juan Pedro and Romero, Roberto},
doi = {10.1093/bioinformatics/btn577},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tarca et al. - 2009 - A novel signaling pathway impact analysis.pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
month = {jan},
number = {1},
pages = {75--82},
pmid = {18990722},
publisher = {Oxford University Press},
title = {{A novel signaling pathway impact analysis}},
url = {/pmc/articles/PMC2732297/ /pmc/articles/PMC2732297/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2732297/},
volume = {25},
year = {2009}
}
@article{Linzer2011,
abstract = {poLCA is a software package for the estimation of latent class and latent class regression models for polytomous outcome variables, implemented in the R statistical computing environment. Both models can be called using a single simple command line. The basic latent class model is a finite mixture model in which the component distributions are assumed to be multi-way cross-classification tables with all variables mutually independent. The latent class regression model further enables the researcher to estimate the effects of covariates on predicting latent class membership. poLCA uses expectation-maximization and Newton-Raphson algorithms to find maximum likelihood estimates of the model parameters.},
author = {Linzer, Drew A. and Lewis, Jeffrey B.},
doi = {10.18637/jss.v042.i10},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Categorical,Concomitant,Latent class analysis,Latent class regression,Polytomous},
month = {jun},
number = {10},
pages = {1--29},
publisher = {American Statistical Association},
title = {{poLCA: An R package for polytomous variable latent class analysis}},
url = {https://www.jstatsoft.org/index.php/jss/article/view/v042i10},
volume = {42},
year = {2011}
}
@article{Mermel2011,
abstract = {We describe methods with enhanced power and specificity to identify genes targeted by somatic copy-number alterations (SCNAs) that drive cancer growth. By separating SCNA profiles into underlying arm-level and focal alterations, we improve the estimation of background rates for each category. We additionally describe a probabilistic method for defining the boundaries of selected-for SCNA regions with user-defined confidence. Here we detail this revised computational approach, GISTIC2.0, and validate its performance in real and simulated datasets. {\textcopyright} 2011 Mermel et al.; licensee BioMed Central Ltd.},
author = {Mermel, Craig H. and Schumacher, Steven E. and Hill, Barbara and Meyerson, Matthew L. and Beroukhim, Rameen and Getz, Gad},
doi = {10.1186/GB-2011-12-4-R41/FIGURES/7},
issn = {14747596},
journal = {Genome Biology},
keywords = {Animal Genetics and Genomics,Bioinformatics,Evolutionary Biology,Human Genetics,Microbial Genetics and Genomics,Plant Genetics and Genomics},
month = {apr},
number = {4},
pages = {1--14},
pmid = {21527027},
publisher = {BioMed Central},
title = {{GISTIC2.0 facilitates sensitive and confident localization of the targets of focal somatic copy-number alteration in human cancers}},
url = {https://genomebiology.biomedcentral.com/articles/10.1186/gb-2011-12-4-r41},
volume = {12},
year = {2011}
}
@misc{Harrell2023,
abstract = {Regression modeling, testing, estimation, validation, graphics, prediction, and typesetting by storing enhanced model design attributes in the fit. 'rms' is a collection of functions that assist with and streamline modeling. It also contains functions for binary and ordinal logistic regression models, ordinal models for continuous Y with a variety of distribution families, and the Buckley-James multiple regression model for right-censored responses, and implements penalized maximum likelihood estimation for logistic and ordinary linear models. 'rms' works with almost any regression model, but it was especially written to work with binary or ordinal regression models, Cox regression, accelerated failure time models, ordinary linear models, the Buckley-James model, generalized least squares for serially or spatially correlated observations, generalized linear models, and quantile regression.},
author = {Harrell, Frank E.},
title = {{rms: Regression Modeling Strategies}},
url = {https://cran.r-project.org/web/packages/rms/index.html},
year = {2023}
}
@article{Gavai2015,
abstract = {Predicting the distribution of metabolic fluxes in biochemical networks is of major interest in systems biology. Several databases provide metabolic reconstructions for different organisms. Software to analyze flux distributions exists, among others for the proprietary MATLAB environment. Given the large user community for the R computing environment, a simple implementation of flux analysis in R appears desirable and will facilitate easy interaction with computational tools to handle gene expression data. We extended the R software package BiGGR, an implementation of metabolic flux analysis in R. BiGGR makes use of public metabolic reconstruction databases, and contains the BiGG database and the reconstruction of human metabolism Recon2 as Systems Biology Markup Language (SBML) objects. Models can be assembled by querying the databases for pathways, genes or reactions of interest. Fluxes can then be estimated by maximization or minimization of an objective function using linear inverse modeling algorithms. Furthermore, BiGGR provides functionality to quantify the uncertainty in flux estimates by sampling the constrained multidimensional flux space. As a result, ensembles of possible flux configurations are constructed that agree with measured data within precision limits. BiGGR also features automatic visualization of selected parts of metabolic networks using hypergraphs, with hyperedge widths proportional to estimated flux values. BiGGR supports import and export of models encoded in SBML and is therefore interoperable with different modeling and analysis tools. As an application example, we calculated the flux distribution in healthy human brain using a model of central carbon metabolism. We introduce a new algorithm termed Least-squares with equalities and inequalities Flux Balance Analysis (Lsei-FBA) to predict flux changes from gene expression changes, for instance during disease. Our estimates of brain metabolic flux pattern with Lsei-FBA for Alzheimer's disease agree with independent measurements of cerebral metabolism in patients. This second version of BiGGR is available from Bioconductor.},
author = {Gavai, Anand K. and Supandi, Farahaniza and Hettling, Hannes and Murrell, Paul and Leunissen, Jack A.M. and {Van Beek}, Johannes H.G.M.},
doi = {10.1371/JOURNAL.PONE.0119016},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {Algorithms,Alzheimer's disease,Brain diseases,Gene expression,Glucose metabolism,Metabolic networks,Metabolites,Network analysis},
month = {mar},
number = {3},
pages = {e0119016},
pmid = {25806817},
publisher = {Public Library of Science},
title = {{Using Bioconductor Package BiGGR for Metabolic Flux Estimation Based on Gene Expression Changes in Brain}},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0119016},
volume = {10},
year = {2015}
}
@misc{Allaire2022,
abstract = {Convert R Markdown documents into a variety of formats.},
author = {Allaire, JJ and Xie, Yihui and McPherson, Jonathan and Luraschi, Javier and Ushey, Kevin and Atkins, Aron and Wickham, Hadley and Cheng, Joe},
title = {{rmarkdown: Dynamic Documents for R}},
url = {https://cran.r-project.org/web/packages/rmarkdown/index.html},
year = {2022}
}
@misc{Barnier2022,
abstract = {HTML formats and templates for 'rmarkdown' documents, with some extra features such as automatic table of contents, lightboxed figures, dynamic crosstab helper.},
author = {Barnier, Julien},
title = {{rmdformats: HTML Output Formats and Templates for 'rmarkdown' Documents}},
url = {https://cran.r-project.org/web/packages/rmdformats/index.html},
year = {2022}
}
@misc{Ripley2022,
abstract = {Functions and datasets to support Venables and Ripley, "Modern Applied Statistics with S" (4th edition, 2002).},
author = {Ripley, Brian},
month = {aug},
publisher = {Comprehensive R Archive Network (CRAN)},
title = {{MASS: Support Functions and Datasets for Venables and Ripley's MASS}},
url = {https://cran.r-project.org/package=MASS},
year = {2022}
}
@misc{Henry2022,
abstract = {A toolbox for working with base types, core R features like the condition system, and core 'Tidyverse' features like tidy evaluation.},
author = {Henry, Lionel and Wickham, Hadley.},
title = {{rlang: Functions for Base Types and Core R and 'Tidyverse' Features}},
url = {https://cran.r-project.org/web/packages/rlang/index.html},
year = {2022}
}
@misc{Gerds2022,
abstract = {Validation of risk predictions obtained from survival models and competing risk models based on censored data using inverse weighting and cross-validation. Most of the 'pec' functionality has been moved to 'riskRegression'.},
author = {Gerds, Thomas A},
title = {{pec: Prediction Error Curves for Risk Prediction Models in Survival Analysis}},
url = {https://cran.r-project.org/web/packages/pec/index.html},
year = {2022}
}
@misc{Xie2022,
abstract = {Provides a general-purpose tool for dynamic report generation in R using Literate Programming techniques.},
author = {Xie, Yihui},
title = {{knitr: A General-Purpose Package for Dynamic Report Generation in R}},
url = {https://cran.r-project.org/web/packages/knitr/index.html},
year = {2022}
}
@article{Benjamini1995,
abstract = {The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses- the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
author = {Benjamini, Yoav and Hochberg, Yosef},
doi = {10.1111/j.2517-6161.1995.tb02031.x},
issn = {0035-9246},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
keywords = {bonferroni‐type procedures,familywise error rate,multiple‐comparison procedures,p‐values},
month = {jan},
number = {1},
pages = {289--300},
publisher = {Wiley},
title = {{Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing}},
volume = {57},
year = {1995}
}
@book{Wickham2016,
address = {New York},
author = {Wickham, Hadley.},
edition = {1},
isbn = {978-3-319-24277-4},
publisher = {Springer-Verlag},
title = {{ggplot2: Elegant Graphics for Data Analysis}},
url = {https://ggplot2.tidyverse.org},
year = {2016}
}
@article{Strobl2009,
abstract = {Recursive partitioning methods have become popular and widely used tools for nonparametric regression and classification in many scientific fields. Especially random forests, which can deal with large numbers of predictor variables even in the presence of complex interactions, have been applied successfully in genetics, clinical medicine, and bioinformatics within the past few years. High-dimensional problems are common not only in genetics, but also in some areas of psychological research, where only a few subjects can be measured because of time or cost constraints, yet a large amount of data is generated for each subject. Random forests have been shown to achieve a high prediction accuracy in such applications and to provide descriptive variable importance measures reflecting the impact of each variable in both main effects and interactions. The aim of this work is to introduce the principles of the standard recursive partitioning methods as well as recent methodological improvements, to illustrate their usage for low and high-dimensional data exploration, but also to point out limitations of the methods and potential pitfalls in their practical application. Application of the methods is illustrated with freely available implementations in the R system for statistical computing. {\textcopyright} 2009 American Psychological Association.},
author = {Strobl, Carolin and Malley, James and Tutz, Gerhard},
doi = {10.1037/A0016973},
issn = {1082989X},
journal = {Psychological methods},
keywords = {classification,prediction,regression,variable importance},
month = {dec},
number = {4},
pages = {323},
pmid = {19968396},
publisher = {NIH Public Access},
title = {{An Introduction to Recursive Partitioning: Rationale, Application and Characteristics of Classification and Regression Trees, Bagging and Random Forests}},
url = {/pmc/articles/PMC2927982/ /pmc/articles/PMC2927982/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2927982/},
volume = {14},
year = {2009}
}
@article{Zhu2022,
abstract = {Purpose:There is an age-related decline in male testosterone production. It is therefore surprising that young men are evaluated for testosterone deficiency with the same cutoff of 300 ng/dL that was developed from samples of older men. Our aim is to describe normative total testosterone levels and age-specific cutoffs for low testosterone levels in men 20 to 44 years old.Materials and Methods:We analyzed the 2011-2016 National Health and Nutrition Examination Surveys, which survey nationally representative samples of United States residents. Men 20 to 44 years old with testosterone levels were included. Men on hormonal medications, with a history of testicular cancer or orchiectomy, and with afternoon/evening laboratory values were excluded. We separated men into 5-year intervals and evaluated the testosterone levels of each age group, and for all men 20 to 44 years old. We used the American Urological Association definition of a "normal testosterone level"(the "middle tertile") to calculate age-specific cutoffs for low testosterone levels.Results:Our final analytic cohort contained 1,486 men. Age-specific middle tertile levels were 409-558 ng/dL (20-24 years old), 413-575 ng/dL (25-29 years old), 359-498 ng/dL (30-34 years old), 352-478 ng/dL (35-39 years old), and 350-473 ng/dL (40-44 years old). Age-specific cutoffs for low testosterone levels were 409, 413, 359, 352, and 350 ng/dL, respectively.Conclusions:Diagnosis of testosterone deficiency has traditionally been performed in an age-indiscriminate manner. However, young men have different testosterone reference ranges than older men. Accordingly, age-specific normative values and cutoffs should be integrated into the evaluation of young men presenting with testosterone deficiency.},
author = {Zhu, Alex and Andino, Juan and Daignault-Newton, Stephanie and Chopra, Zoey and Sarma, Aruna and Dupree, James M.},
doi = {10.1097/JU.0000000000002928},
issn = {1527-3792},
journal = {The Journal of urology},
keywords = {Adult,Aged,Alex Zhu,Humans,Hypogonadism* / drug therapy,James M Dupree,Juan Andino,MEDLINE,Male,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Nutrition Surveys,PubMed Abstract,Reference Values,Testicular Neoplasms* / drug therapy,Testosterone / therapeutic use,United States / epidemiology,Young Adult,doi:10.1097/JU.0000000000002928,pmid:36282060},
month = {dec},
number = {6},
pages = {1295--1301},
pmid = {36282060},
publisher = {J Urol},
title = {{What Is a Normal Testosterone Level for Young Men? Rethinking the 300 ng/dL Cutoff for Testosterone Deficiency in Men 20-44 Years Old}},
url = {https://pubmed.ncbi.nlm.nih.gov/36282060/},
volume = {208},
year = {2022}
}
@article{Hothorn2006,
abstract = {Recursive binary partitioning is a popular tool for regression analysis. Two fundamental problems of exhaustive search procedures usually applied to fit such models have been known for a long time: overfitting and a selection bias towards covariates with many possible splits or missing values. While pruning procedures are able to solve the overfitting problem, the variable selection bias still seriously affects the interpretability of tree-structured regression models. For some special cases unbiased procedures have been suggested, however lacking a common theoretical foundation. We propose a unified framework for recursive partitioning which embeds tree-structured regression models into a well defined theory of conditional inference procedures. Stopping criteria based on multiple test procedures are implemented and it is shown that the predictive performance of the resulting trees is as good as the performance of established exhaustive search procedures. It turns out that the partitions and therefore the models induced by both approaches are structurally different, confirming the need for an unbiased variable selection. Moreover, it is shown thai the prediction accuracy of trees with early stopping is equivalent to the prediction accuracy of pruned trees with unbiased variable selection. The methodology presented here is applicable to all kinds of regression problems, including nominal, ordinal, numeric, censored as well as multivariate response variables and arbitrary measurement scales of the covariates. Data from studies on glaucoma classification, node positive breast cancer survival and mammography experience are re-analyzed. {\textcopyright} 2006 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
author = {Hothorn, Torsten and Hornik, Kurt and Zeileis, Achim},
doi = {10.1198/106186006X133933},
issn = {10618600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Multiple testing,Multivariate regression trees,Ordinal regression trees,Permutation tests,Variable selection},
number = {3},
pages = {651--674},
publisher = {Taylor & Francis},
title = {{Unbiased recursive partitioning: A conditional inference framework}},
url = {https://www.tandfonline.com/doi/abs/10.1198/106186006X133933},
volume = {15},
year = {2006}
}
@article{Hanzelmann2013,
abstract = {Background: Gene set enrichment (GSE) analysis is a popular framework for condensing information from gene expression profiles into a pathway or signature summary. The strengths of this approach over single gene analysis include noise and dimension reduction, as well as greater biological interpretability. As molecular profiling experiments move beyond simple case-control studies, robust and flexible GSE methodologies are needed that can model pathway activity within highly heterogeneous data sets. Results: To address this challenge, we introduce Gene Set Variation Analysis (GSVA), a GSE method that estimates variation of pathway activity over a sample population in an unsupervised manner. We demonstrate the robustness of GSVA in a comparison with current state of the art sample-wise enrichment methods. Further, we provide examples of its utility in differential pathway activity and survival analysis. Lastly, we show how GSVA works analogously with data from both microarray and RNA-seq experiments. Conclusions: GSVA provides increased power to detect subtle pathway activity changes over a sample population in comparison to corresponding methods. While GSE methods are generally regarded as end points of a bioinformatic analysis, GSVA constitutes a starting point to build pathway-centric models of biology. Moreover, GSVA contributes to the current need of GSE methods for RNA-seq data. GSVA is an open source software package for R which forms part of the Bioconductor project and can be downloaded at http://www.bioconductor.org. {\textcopyright} 2013 H{\"{a}}nzelmann et al.; licensee BioMed Central Ltd.},
author = {H{\"{a}}nzelmann, Sonja and Castelo, Robert and Guinney, Justin},
doi = {10.1186/1471-2105-14-7},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/H{\"{a}}nzelmann, Castelo, Guinney - 2013 - GSVA Gene set variation analysis for microarray and RNA-Seq data.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Bioinformatics,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
month = {jan},
number = {1},
pages = {7},
pmid = {23323831},
publisher = {BioMed Central},
title = {{GSVA: Gene set variation analysis for microarray and RNA-Seq data}},
url = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-7},
volume = {14},
year = {2013}
}
@article{Sturm2020,
abstract = {Since the performance of in silico approaches for estimating immune-cell fractions from bulk RNA-seq data can vary, it is often advisable to compare results of several methods. Given numerous dependencies and differences in input and output format of the various computational methods, comparative analyses can become quite complex. This motivated us to develop immunedeconv, an R package providing uniform and user-friendly access to seven state-of-the-art computational methods for deconvolution of cell-type fractions from bulk RNA-seq data. Here, we show how immunedeconv can be installed and applied to a typical dataset. First, we give an example for obtaining cell-type fractions using quanTIseq. Second, we show how dimensionless scores produced by MCP-counter can be used for cross-sample comparisons. For each of these examples, we provide R code illustrating how immunedeconv results can be summarized graphically.},
author = {Sturm, Gregor and Finotello, Francesca and List, Markus},
doi = {10.1007/978-1-0716-0327-7_16},
issn = {1940-6029},
journal = {Methods in molecular biology (Clifton, N.J.)},
keywords = {Computer Simulation,Francesca Finotello,Gene Expression Profiling / methods,Genomics / methods*,Gregor Sturm,Humans,Immune System / cytology,Immune System / immunology,Immune System / metabolism,MEDLINE,Markus List,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neoplasms / genetics*,Neoplasms / immunology,PubMed Abstract,RNA / methods*,Sequence Analysis,Software*,doi:10.1007/978-1-0716-0327-7_16,pmid:32124323},
pages = {223--232},
pmid = {32124323},
publisher = {Methods Mol Biol},
title = {{Immunedeconv: An R Package for Unified Access to Computational Methods for Estimating Immune Cell Fractions from Bulk RNA-Sequencing Data}},
url = {https://pubmed.ncbi.nlm.nih.gov/32124323/},
volume = {2120},
year = {2020}
}
@inproceedings{Todorov2013,
abstract = {The main drawback of principal component analysis (PCA) especially for applications in high dimensions is that the extracted components are linear combinations of all input variables. To facilitate the interpretability of PCA various sparse methods have been proposed recently. However all these methods might suffer from the influence of outliers present in the data. An algorithm to compute sparse and robust PCA was recently proposed by Croux et al. We compare this method to standard (non-sparse) classical and robust PCA and several other sparse methods. The considered methods are illustrated on a real data example and compared in a simulation experiment. It is shown that the robust sparse method preserves the sparsity and at the same time provides protection against contamination. {\textcopyright} 2013 Springer-Verlag.},
author = {Todorov, Valentin and Filzmoser, Peter},
booktitle = {Advances in Intelligent Systems and Computing},
doi = {10.1007/978-3-642-33042-1_31},
isbn = {9783642330414},
issn = {21945357},
keywords = {Principcal component analysis,robust statistics},
pages = {283--291},
publisher = {Springer Verlag},
title = {{Comparing classical and robust sparse PCA}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-33042-1_31},
volume = {190 AISC},
year = {2013}
}
@misc{Hothorn2022,
abstract = {A computational toolbox for recursive partitioning. The core of the package is ctree(), an implementation of conditional inference trees which embed tree-structured regression models into a well defined theory of conditional inference procedures. This non-parametric class of regression trees is applicable to all kinds of regression problems, including nominal, ordinal, numeric, censored as well as multivariate response variables and arbitrary measurement scales of the covariates. Based on conditional inference trees, cforest() provides an implementation of Breiman's random forests. The function mob() implements an algorithm for recursive partitioning based on parametric models (e.g. linear models, GLMs or survival regression) employing parameter instability tests for split selection. Extensible functionality for visualizing tree-structured regression models is available. The methods are described in Hothorn et al. (2006) <doi:10.1198/106186006X133933>, Zeileis et al. (2008) <doi:10.1198/106186008X319331> and Strobl et al. (2007) <doi:10.1186/1471-2105-8-25>.},
author = {Hothorn, Thorsten and Hornik, Kurt and Strobl, Carolin and Zeileis, Achim},
title = {{party: A Laboratory for Recursive Partytioning}},
url = {https://cran.r-project.org/web/packages/party/index.html},
year = {2022}
}
@article{Kuhn2008,
abstract = {The caret package, short for classification and regression training, contains numerous tools for developing predictive models using the rich set of models available in R. The package focuses on simplifying model training and tuning across a wide variety of modeling techniques. It also includes methods for pre-processing training data, calculating variable importance, and model visualizations. An example from computational chemistry is used to illustrate the functionality on a real data set and to benchmark the benefits of parallel processing with several types of models.},
author = {Kuhn, Max},
doi = {10.18637/jss.v028.i05},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Model building,NetWorkSpaces,Parallel processing,R,Tuning parameters},
number = {5},
pages = {1--26},
publisher = {American Statistical Association},
title = {{Building predictive models in R using the caret package}},
volume = {28},
year = {2008}
}
@article{Bandeen-roche1997,
abstract = {Quantifying human health and functioning poses significant challenges in many research areas. Commonly in the social and behavioral sciences and increasingly in epidemiologic research, multiple indicators are utilized as responses in lieu of an obvious single measure for an outcome of interest. In this article we study the concomitant latent class model for analyzing such multivariate categorical outcome data. We develop practical theory for reducing and identifying such models. We detail parameter and standard error fitting that parallels standard latent class methodology, thus supplementing the approach proposed by Dayton and Macready. We propose and study diagnostic strategies, exemplifying our methods using physical disability data from an ongoing gerontologic study. Throughout, the focus of our work is on applications for which a primary goal is to study the association between health or functioning and covariates. {\textcopyright} 1997 Taylor & Francis Group, LLC.},
author = {Bandeen-roche, Karen and Miglioretti, Diana L. and Zeger, Scott L. and Rathouz, Paul J.},
doi = {10.1080/01621459.1997.10473658},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Categorical data,Diagnosis,Identifiability,Latent class,Link function,Mixture model},
month = {dec},
number = {440},
pages = {1375--1386},
publisher = {Taylor & Francis Group},
title = {{Latent variable regression for multiple discrete outcomes}},
url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1997.10473658},
volume = {92},
year = {1997}
}
@article{Breiman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, * * *, 148-156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
author = {Breiman, Leo},
doi = {10.1023/A:1010933404324},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Breiman - 2001 - Random forests.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {Classification,Ensemble,Regression},
month = {oct},
number = {1},
pages = {5--32},
publisher = {Springer},
title = {{Random forests}},
url = {https://link.springer.com/article/10.1023/A:1010933404324},
volume = {45},
year = {2001}
}
@article{Strobl2007,
abstract = {Background: Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories. Results: Simulation studies are presented illustrating that, when random forest variable importance measures are used with data of varying types, the results are misleading because suboptimal predictor variables may be artificially preferred in variable selection. The two mechanisms underlying this deficiency are biased variable selection in the individual classification trees used to build the random forest on one hand, and effects induced by bootstrap sampling with replacement on the other hand. Conclusion: We propose to employ an alternative implementation of random forests, that provides unbiased variable selection in the individual classification trees. When this method is applied using subsampling without replacement, the resulting variable importance measures can be used reliably for variable selection even in situations where the potential predictor variables vary in their scale of measurement or their number of categories. The usage of both random forest algorithms and their variable importance measures in the R system for statistical computing is illustrated and documented thoroughly in an application re-analyzing data from a study on RNA editing. Therefore the suggested method can be applied straightforwardly by scientists in bioinformatics research. {\textcopyright} 2007 Strobl et al; licensee BioMed Central Ltd.},
author = {Strobl, Carolin and Boulesteix, Anne Laure and Zeileis, Achim and Hothorn, Torsten},
doi = {10.1186/1471-2105-8-25/FIGURES/11},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Bioinformatics,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
month = {jan},
number = {1},
pages = {1--21},
pmid = {17254353},
publisher = {BioMed Central},
title = {{Bias in random forest variable importance measures: Illustrations, sources and a solution}},
url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-25},
volume = {8},
year = {2007}
}
@book{Xie2016,
abstract = {bookdown: Authoring Books and Technical Documents with R Markdown presents a much easier way to write books and technical publications than traditional tools such as LaTeX and Word. The bookdown package inherits the simplicity of syntax and flexibility for data analysis from R Markdown, and extends R Markdown for technical writing, so that you can make better use of document elements such as figures, tables, equations, theorems, citations, and references. Similar to LaTeX, you can number and cross-reference these elements with bookdown. Your document can even include live examples so readers can interact with them while reading the book. The book can be rendered to multiple output formats, including LaTeX/PDF, HTML, EPUB, and Word, thus making it easy to put your documents online. The style and theme of these output formats can be customized. We used books and R primarily for examples in this book, but bookdown is not only for books or R. Most features introduced in this book also apply to other types of publications: journal papers, reports, dissertations, course handouts, study notes, and even novels. You do not have to use R, either. Other choices of computing languages include Python, C, C plus plus, SQL, Bash, Stan, JavaScript, and so on, although R is best supported. You can also leave out computing, for example, to write a fiction. This book itself is an example of publishing with bookdown and R Markdown, and its source is fully available on GitHub.},
author = {Xie, Yihui},
booktitle = {Bookdown: Authoring Books and Technical Documents with R Markdown},
doi = {10.1201/9781315204963},
isbn = {9781351792608},
pages = {1--113},
title = {{Bookdown: Authoring books and technical documents with R Markdown}},
year = {2016}
}
@article{Milose2012,
abstract = {Testis cancer is one of the few solid organ malignancies for which reliable serum tumor markers are available to help guide disease management. Human chorionic gonadotropin, alpha fetoprotein, and lactate dehydrogenase play crucial roles in diagnosis, staging, prognosis, monitoring treatment response, and surveillance of seminomatous and nonseminomatous germ cell tumors. Herein we discuss the clinical applications of germ cell tumor markers, the limitations of these markers in the management of this disease, and additional serum molecules that have been identified with potential roles as novel germ cell tumor markers. {\textcopyright} 2012 Milose et al, publisher and licensee Dove Medical Press Ltd.},
author = {Milose, Jaclyn C. and Filson, Christopher P. and Weizer, Alon Z. and Hafez, Khaled S. and Montgomery, Jeffrey S.},
doi = {10.2147/OAJU.S15063},
issn = {11791551},
journal = {Open Access Journal of Urology},
keywords = {AFP,Diagnosis,Surveillance,Testicular cancer,Tumor markers,bhCG},
month = {dec},
number = {1},
pages = {1},
pmid = {24198649},
publisher = {Dove Press},
title = {{Role of biochemical markers in testicular cancer: diagnosis, staging, and surveillance}},
url = {/pmc/articles/PMC3818947/ /pmc/articles/PMC3818947/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3818947/},
volume = {4},
year = {2012}
}
@misc{Kassambara2021,
author = {Kassambara, Alboukadel},
title = {{rstatix: Pipe-Friendly Framework for Basic Statistical Tests}},
url = {https://cran.r-project.org/package=rstatix},
year = {2021}
}
@article{King2016,
abstract = {Genome-scale metabolic models are mathematically-structured knowledge bases that can be used to predict metabolic pathway usage and growth phenotypes. Furthermore, they can generate and test hypotheses when integrated with experimental data. To maximize the value of these models, centralized repositories of high-quality models must be established, models must adhere to established standards and model components must be linked to relevant databases. Tools for model visualization further enhance their utility. To meet these needs, we present BiGG Models (http://bigg.ucsd.edu), a completely redesigned Biochemical, Genetic and Genomic knowledge base. BiGG Models contains more than 75 high-quality, manually-curated genome-scale metabolic models. On the website, users can browse, search and visualize models. BiGG Models connects genome-scale models to genome annotations and external databases. Reaction and metabolite identifiers have been standardized across models to conform to community standards and enable rapid comparison across models. Furthermore, BiGG Models provides a comprehensive application programming interface for accessing BiGG Models with modeling and analysis tools. As a resource for highly curated, standardized and accessible models of metabolism, BiGG Models will facilitate diverse systems biology studies and support knowledge-based analysis of diverse experimental data.},
author = {King, Zachary A. and Lu, Justin and Dr{\"{a}}ger, Andreas and Miller, Philip and Federowicz, Stephen and Lerman, Joshua A. and Ebrahim, Ali and Palsson, Bernhard O. and Lewis, Nathan E.},
doi = {10.1093/NAR/GKV1049},
isbn = {515/2502593},
issn = {0305-1048},
journal = {Nucleic Acids Research},
keywords = {metabolism},
month = {jan},
number = {D1},
pages = {D515--D522},
pmid = {26476456},
publisher = {Oxford Academic},
title = {{BiGG Models: A platform for integrating, standardizing and sharing genome-scale models}},
url = {https://academic.oup.com/nar/article/44/D1/D515/2502593},
volume = {44},
year = {2016}
}
@misc{Wickham2022,
abstract = {Import excel files into R. Supports '.xls' via the embedded 'libxls' C library <https://github.com/libxls/libxls> and '.xlsx' via the embedded 'RapidXML' C++ library <https://rapidxml.sourceforge.net/>. Works on Windows, Mac and Linux without external dependencies.},
author = {Wickham, Hadley and Bryan, Jennifer and Posit, PBC and Kalicinski, Marcin and Komarov, Valery and Leitienne, Christophe and Colbert, Bob and Hoerl, David and Miller, Evan},
title = {{readxl: Read Excel Files}},
url = {https://cran.r-project.org/web/packages/readxl/index.html},
year = {2022}
}
@article{Wright2017,
abstract = {We introduce the C++ application and R package ranger. The software is a fast implementation of random forests for high dimensional data. Ensembles of classification, regression and survival trees are supported. We describe the implementation, provide examples, validate the package with a reference implementation, and compare runtime and memory usage with other implementations. The new software proves to scale best with the number of features, samples, trees, and features tried for splitting. Finally, we show that ranger is the fastest and most memory efficient implementation of random forests to analyze data on the scale of a genome-wide association study.},
archivePrefix = {arXiv},
arxivId = {1508.04409},
author = {Wright, Marvin N. and Ziegler, Andreas},
doi = {10.18637/JSS.V077.I01},
eprint = {1508.04409},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wright, Ziegler - 2017 - ranger A Fast Implementation of Random Forests for High Dimensional Data in C and R.pdf:pdf},
issn = {1548-7660},
journal = {Journal of Statistical Software},
keywords = {R,Rcpp,classification,machine learning,random forests,recursive partitioning,survival analysis},
month = {mar},
number = {1},
pages = {1--17},
publisher = {American Statistical Association},
title = {{ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R}},
url = {https://www.jstatsoft.org/index.php/jss/article/view/v077i01},
volume = {77},
year = {2017}
}
@article{Harrell1996,
abstract = {Multivariable regression models are powerful tools that are used frequently in studies of clinical outcomes. These models can use a mixture of categorical and continuous variables and can handle partially observed (censored) responses. However, uncritical application of modelling techniques can result in models that poorly fit the dataset at hand, or, even more likely, inaccurately predict outcomes on new subjects. One must know how to measure qualities of a model's fit in order to avoid poorly fitted or overfitted models. Measurement of predictive accuracy can be difficult for survival time data in the presence of censoring. We discuss an easily interpretable index of predictive discrimination as well as methods for assessing calibration of predicted survival probabilities. Both types of predictive accuracy should be unbiasedly validated using bootstrapping or cross-validation, before using predictions in a new data series. We discuss some of the hazards of poorly fitted and overfitted regression models and present one modelling strategy that avoids many of the problems discussed. The methods described are applicable to all regression models, but are particularly needed for binary, ordinal, and time-to-event outcomes. Methods are illustrated with a survival analysis in prostate cancer using Cox regression.},
author = {Harrell, Frank E. and Lee, Kerry L. and Mark, Daniel B.},
doi = {10.1002/(SICI)1097-0258(19960229)15:4<361::AID-SIM168>3.0.CO;2-4},
issn = {02776715},
journal = {Statistics in Medicine},
keywords = {pmid:8668867, doi:10.1002/(SICI)1097-0258(19960229},
month = {feb},
number = {4},
pages = {361--387},
pmid = {8668867},
publisher = {Stat Med},
title = {{Multivariable prognostic models: Issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors}},
url = {https://pubmed.ncbi.nlm.nih.gov/8668867/},
volume = {15},
year = {1996}
}
@misc{Gagolewski2021,
abstract = {A collection of character string/text/natural language processing tools for pattern searching (e.g., with 'Java'-like regular expressions or the 'Unicode' collation algorithm), random string generation, case mapping, string transliteration, concatenation, sorting, padding, wrapping, Unicode normalisation, date-time formatting and parsing, and many more. They are fast, consistent, convenient, and - thanks to 'ICU' (International Components for Unicode) - portable across all locales and platforms.},
author = {Gagolewski, Marek and Tartanus, Bartek},
title = {{Package 'stringi'}},
url = {https://cran.r-project.org/web/packages/stringi/index.html http://cran.ism.ac.jp/web/packages/stringi/stringi.pdf},
year = {2021}
}
@article{Graf1999,
abstract = {Prognostic classification schemes have often been used in medical applications, but rarely subjected to a rigorous examination of their adequacy. For survival data, the statistical methodology to assess such schemes consists mainly of a range of ad hoc approaches, and there is an alarming lack of commonly accepted standards in this field. We review these methods and develop measures of inaccuracy which may be calculated in a validation study in order to assess the usefulness of estimated patient-specific survival probabilities associated with a prognostic classification scheme. These measures are meaningful even when the estimated probabilities are misspecified, and asymptotically they are not affected by random censorship. In addition, they can be used to derive R2-type measures of explained residual variation. A breast cancer study will serve for illustration throughout the paper.},
author = {Graf, Erika and Schmoor, Claudia and Sauerbrei, Willi and Schumacher, Martin},
doi = {10.1002/(sici)1097-0258(19990915/30)18:17/18<2529::aid-sim274>3.0.co;2-5},
issn = {0277-6715},
journal = {Statistics in Medicine},
keywords = {Europe PMC,Europe PubMed Central,ORCIDs,REST APIs,abstracts,bioinformatics,biological patents,biomedical journals,biomedical research,citation networks,citation search,clinical guidelines,full text,journal articles,life sciences,literature search,open access,research articles,text mining},
month = {sep},
number = {17-18},
pages = {2529--2545},
pmid = {10474158},
publisher = {John Wiley and Sons Ltd},
title = {{Assessment and comparison of prognostic classification schemes for survival data.}},
url = {https://europepmc.org/article/med/10474158},
volume = {18},
year = {1999}
}
@article{Finotello2019,
abstract = {We introduce quanTIseq, a method to quantify the fractions of ten immune cell types from bulk RNA-sequencing data. quanTIseq was extensively validated in blood and tumor samples using simulated, flow cytometry, and immunohistochemistry data. quanTIseq analysis of 8000 tumor samples revealed that cytotoxic T cell infiltration is more strongly associated with the activation of the CXCR3/CXCL9 axis than with mutational load and that deconvolution-based cell scores have prognostic value in several solid cancers. Finally, we used quanTIseq to show how kinase inhibitors modulate the immune contexture and to reveal immune-cell types that underlie differential patients' responses to checkpoint blockers. Availability: quanTIseq is available at http://icbi.at/quantiseq.},
author = {Finotello, Francesca and Mayer, Clemens and Plattner, Christina and Laschober, Gerhard and Rieder, DIetmar and Hackl, Hubert and Krogsdam, Anne and Loncova, Zuzana and Posch, Wilfried and Wilflingseder, Doris and Sopper, Sieghart and Ijsselsteijn, Marieke and Brouwer, Thomas P. and Johnson, Douglas and Xu, Yaomin and Wang, Yu and Sanders, Melinda E. and Estrada, Monica V. and Ericsson-Gonzalez, Paula and Charoentong, Pornpimol and Balko, Justin and {De Miranda}, Noel Filipe Da Cunha Carvahlo and Trajanoski, Zlatko},
doi = {10.1186/s13073-019-0638-6},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Finotello et al. - 2019 - Molecular and pharmacological modulators of the tumor immune contexture revealed by deconvolution of RNA-seq d.pdf:pdf},
issn = {1756994X},
journal = {Genome Medicine},
keywords = {Cancer immunology,Deconvolution,Immune contexture,Immunotherapy,RNA-seq},
month = {may},
number = {1},
pages = {34},
pmid = {31126321},
publisher = {BioMed Central Ltd.},
title = {{Molecular and pharmacological modulators of the tumor immune contexture revealed by deconvolution of RNA-seq data}},
url = {https://genomemedicine.biomedcentral.com/articles/10.1186/s13073-019-0638-6},
volume = {11},
year = {2019}
}
@article{Friedman2010,
abstract = {We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multinomial regression problems while the penalties include l1 (the lasso), l2 (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.},
author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
doi = {10.18637/jss.v033.i01},
file = {:C\:/Users/piotr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedman, Hastie, Tibshirani - 2010 - Regularization paths for generalized linear models via coordinate descent.pdf:pdf},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Coordinate-descent,Elastic net,L1 penalty,Lasso,Logistic regression,Regularization path},
month = {feb},
number = {1},
pages = {1--22},
pmid = {20808728},
publisher = {University of California at Los Angeles},
title = {{Regularization paths for generalized linear models via coordinate descent}},
url = {https://www.jstatsoft.org/index.php/jss/article/view/v033i01/v33i01.pdf https://www.jstatsoft.org/index.php/jss/article/view/v033i01},
volume = {33},
year = {2010}
}
